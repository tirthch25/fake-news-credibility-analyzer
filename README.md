# ğŸ“° Fake News Credibility Analyzer

An end-to-end **Explainable NLP-based Machine Learning application** that classifies news articles as **Real** or **Fake**, while also providing **word-level explanations** for each prediction.

This project focuses on **trustworthy and interpretable AI**, combining text classification, model explainability, and a deployed web interface.

---

## ğŸš€ Features

- ğŸ” Fake vs Real news classification
- ğŸ§  NLP-based text preprocessing
- ğŸ“Š TF-IDF feature extraction
- ğŸ¤– Logistic Regression model
- ğŸ“ˆ Model evaluation & error analysis
- ğŸ§© Explainable AI (word-level contribution)
- ğŸŒ Interactive Streamlit web application

---

## ğŸ§  Why This Project?

Fake news spreads rapidly and can significantly influence public opinion.  
This project not only predicts whether a news article is fake or real, but also **explains why**, making the system transparent, interpretable, and trustworthy.

---

## ğŸ—‚ï¸ Project Structure
```
fake-news-credibility-analyzer/
â”‚
â”œâ”€â”€ app/
â”‚ â””â”€â”€ app.py # Streamlit web application
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ fake_news_model.pkl # Trained ML model
â”‚ â””â”€â”€ tfidf_vectorizer.pkl # TF-IDF vectorizer
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb
â”‚ â”œâ”€â”€ 02_text_preprocessing.ipynb
â”‚ â”œâ”€â”€ 03_model_training.ipynb
â”‚ â”œâ”€â”€ 04_model_evaluation.ipynb
â”‚ â””â”€â”€ 05_model_explainability.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE

```

---

## ğŸ“Š Dataset

**Source:** Kaggle â€“ Fake and Real News Dataset  
ğŸ”— https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset

### Dataset Files
- `Fake.csv` â€“ Fake news articles  
- `True.csv` â€“ Real news articles (Reuters)

### Columns
- `title`
- `text`
- `subject`
- `date`

### Labels
- `0` â†’ Fake News  
- `1` â†’ Real News  

âš ï¸ **Note:**  
Due to GitHub file size limits, raw and processed datasets are **not included** in this repository.

---

## ğŸ“¦ Dataset Setup (Required)

1. Download the dataset from Kaggle:
   https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset

2. Place the files locally as:
    data/raw/Fake.csv
    data/raw/True.csv

3. Run the notebooks in order to regenerate processed datasets.

---

## ğŸ”„ Workflow

1. **Data Exploration**
   - Dataset inspection
   - Class distribution analysis
   - Text length analysis

2. **Text Preprocessing**
   - Lowercasing
   - URL & punctuation removal
   - Stopword removal
   - Lemmatization

3. **Feature Engineering**
   - TF-IDF Vectorization
   - Unigrams & bigrams

4. **Model Training**
   - Logistic Regression
   - Stratified train-test split

5. **Model Evaluation**
   - Accuracy, Precision, Recall, F1-score
   - Confusion Matrix
   - Error analysis

6. **Explainable AI**
   - Feature weight analysis
   - Word-level contribution to predictions

7. **Deployment**
   - Streamlit web application

---

## ğŸ“ˆ Model Performance

- **Accuracy:** ~94â€“96%
- Balanced performance across Fake and Real classes
- Strong generalization on unseen articles

---

## ğŸ” Explainability Example

- Words such as **breaking**, **shocking**, **revelation** push predictions toward **Fake**
- Words such as **reuters**, **official**, **statement** push predictions toward **Real**

This avoids black-box predictions and improves user trust.

---

## ğŸŒ Streamlit Application

**Input:** Paste a news article  
**Output:**
- Credibility label (Real / Fake)
- Confidence score
- Word-level explanation

---

## â–¶ï¸ How to Run Locally

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/tirthch25/fake-news-credibility-analyzer.git
cd fake-news-credibility-analyzer
```

### 2ï¸âƒ£ Install Dependencies
```
python -m pip install -r requirements.txt
```
### 3ï¸âƒ£ Download NLTK Resources (Once)
```
python -c "import nltk; nltk.download('stopwords'); nltk.download('wordnet')"
```
### 4ï¸âƒ£ Run Streamlit App
```
python -m streamlit run app/app.py
```

### 5ï¸âƒ£Open in browser:
```
http://localhost:8501
```
---
## ğŸ› ï¸ Tech Stack

- Python
- Pandas, NumPy
- Scikit-learn
- NLTK
- Streamlit
- TF-IDF
- Logistic Regression
---

### ğŸ“Œ Future Enhancements

- BERT-based text classification
- SHAP-based explainability
- Multilingual fake news detection
- Cloud deployment (Streamlit Cloud / Hugging Face Spaces)
---
### ğŸ‘¨â€ğŸ’» Author

- Tirth Chankeshwara
- Engineering Student | Data Analyst | AI/ML Enthusiast
